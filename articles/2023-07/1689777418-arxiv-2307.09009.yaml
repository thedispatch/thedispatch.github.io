{
  "uuid": "4a0f6cfa-d341-4eed-94c2-fb4b47bb79ab",
  "version": "0.1",
  "sources": [
    {
      "id": "2307.09009",
      "url": "https://arxiv.org/abs/2307.09009",
      "site": "arxiv"
    }
  ],
  "components": [
    {
      "source_url": "https://arxiv.org/abs/2307.09009",
      "type": "abstract",
      "content": "How is ChatGPT's behavior changing over time?\n\nAuthors:Lingjiao Chen, Matei Zaharia, James Zou\n\nGPT-3.5 and GPT-4 are the two most widely used large language model (LLM)\nservices. However, when and how these models are updated over time is opaque.\nHere, we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 on\nfour diverse tasks: 1) solving math problems, 2) answering sensitive/dangerous\nquestions, 3) generating code and 4) visual reasoning. We find that the\nperformance and behavior of both GPT-3.5 and GPT-4 can vary greatly over time.\nFor example, GPT-4 (March 2023) was very good at identifying prime numbers\n(accuracy 97.6%) but GPT-4 (June 2023) was very poor on these same questions\n(accuracy 2.4%). Interestingly GPT-3.5 (June 2023) was much better than GPT-3.5\n(March 2023) in this task. GPT-4 was less willing to answer sensitive questions\nin June than in March, and both GPT-4 and GPT-3.5 had more formatting mistakes\nin code generation in June than in March. Overall, our findings shows that the\nbehavior of the same LLM service can change substantially in a relatively short\namount of time, highlighting the need for continuous monitoring of LLM quality.\n\n                         Skip to main content       We are hiring   We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate        >  cs  > arXiv:2307.09009       Help | Advanced Search      All fields  Title  Author  Abstract  Comments  Journal reference  ACM classification  MSC classification  Report number  arXiv identifier  DOI  ORCID  arXiv author ID  Help pages  Full text      Search                        GO        quick links   Login  Help Pages  About               Computer Science > Computation and Language    arXiv:2307.09009 (cs)     [Submitted on 18 Jul 2023]  Title: How is ChatGPT's behavior changing over time?  Authors: Lingjiao Chen , Matei Zaharia , James Zou  Download a PDF of the paper titled How is ChatGPT's behavior changing over time?, by Lingjiao Chen and Matei Zaharia and James Zou  Download PDF   Abstract: GPT-3.5 and GPT-4 are the two most widely used large language model (LLM)\nservices. However, when and how these models are updated over time is opaque.\nHere, we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 on\nfour diverse tasks: 1) solving math problems, 2) answering sensitive/dangerous\nquestions, 3) generating code and 4) visual reasoning. We find that the\nperformance and behavior of both GPT-3.5 and GPT-4 can vary greatly over time.\nFor example, GPT-4 (March 2023) was very good at identifying prime numbers\n(accuracy 97.6%) but GPT-4 (June 2023) was very poor on these same questions\n(accuracy 2.4%). Interestingly GPT-3.5 (June 2023) was much better than GPT-3.5\n(March 2023) in this task. GPT-4 was less willing to answer sensitive questions\nin June than in March, and both GPT-4 and GPT-3.5 had more formatting mistakes\nin code generation in June than in March. Overall, our findings shows that the\nbehavior of the same LLM service can change substantially in a relatively short\namount of time, highlighting the need for continuous monitoring of LLM quality.     Subjects:   Computation and Language (cs.CL) ; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)   Cite as:  arXiv:2307.09009 [cs.CL]      (or  arXiv:2307.09009v1 [cs.CL] for this version)       https://doi.org/10.48550/arXiv.2307.09009     Focus to learn more     arXiv-issued DOI via DataCite         Submission history From: Lingjiao Chen [ view email ]  [v1] Tue, 18 Jul 2023 06:56:08 UTC (536 KB)        Full-text links:  Download:   Download a PDF of the paper titled How is ChatGPT's behavior changing over time?, by Lingjiao Chen and Matei Zaharia and James Zou  PDF  Other formats  ( license )    Current browse context: cs.CL    <\u00a0prev   |   next\u00a0>    new  |  recent  |  2307  Change to browse by:  cs  cs.AI  cs.LG      References & Citations   NASA ADS Google Scholar  Semantic Scholar      a  export BibTeX citation  Loading...      BibTeX formatted citation  \u00d7    loading...    Data provided by:       Bookmark             Bibliographic Tools   Bibliographic and Citation Tools        Bibliographic Explorer Toggle     Bibliographic Explorer  ( What is the Explorer? )         Litmaps Toggle     Litmaps  ( What is Litmaps? )         scite.ai Toggle     scite Smart Citations  ( What are Smart Citations? )          Code, Data, Media   Code, Data and Media Associated with this Article        Links to Code Toggle     CatalyzeX Code Finder for Papers  ( What is CatalyzeX? )         DagsHub Toggle     DagsHub  ( What is DagsHub? )         Links to Code Toggle     Papers with Code  ( What is Papers with Code? )         ScienceCast Toggle     ScienceCast  ( What is ScienceCast? )            Demos   Demos        Replicate Toggle     Replicate  ( What is Replicate? )         Spaces Toggle     Hugging Face Spaces  ( What is Spaces? )         Related Papers   Recommenders and Search Tools        Link to Influence Flower     Influence Flower  ( What are Influence Flowers? )         Connected Papers Toggle     Connected Papers  ( What is Connected Papers? )         Core recommender toggle     CORE Recommender  ( What is CORE? )       Author  Venue  Institution  Topic               About arXivLabs     arXivLabs: experimental projects with community collaborators  arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.  Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.  Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs .            Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )              About  Help       Click here to contact arXiv  Contact    Click here to subscribe  Subscribe             Copyright  Privacy Policy      Web Accessibility Assistance    arXiv Operational Status Get status notifications via email or slack              "
    },
    {
      "source_url": "https://arxiv.org/abs/2307.09009",
      "type": "generated",
      "content": "How is ChatGPT's behavior changing over time?\n\nBy Lingjiao Chen, Matei Zaharia, James Zou\n\nA new research paper titled \"How is ChatGPT's behavior changing over time?\" explores the evolution of two widely used large language models (LLMs), GPT-3.5 and GPT-4. Authored by Lingjiao Chen, Matei Zaharia, and James Zou, the paper delves into the opaque nature of updates made to these models over time. The authors evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 across four diverse tasks: solving math problems, answering sensitive/dangerous questions, generating code, and visual reasoning.\n\nThe researchers discovered that both GPT-3.5 and GPT-4 exhibit significant variations in performance and behavior over time. For instance, GPT-4 (March 2023) displayed an impressive accuracy of 97.6% when identifying prime numbers. However, GPT-4's performance on the same task dropped drastically to a mere 2.4% accuracy in June 2023. Interestingly, GPT-3.5 (June 2023) outperformed its March 2023 counterpart in this particular task.\n\nAnother noteworthy finding was that GPT-4 became less willing to answer sensitive questions in June compared to March. Additionally, both GPT-4 and GPT-3.5 exhibited more formatting mistakes in code generation in June than in March. These observations highlight the dynamic nature of LLM behavior and the necessity for continuous monitoring of their quality.\n\nThe researchers emphasize the importance of understanding how LLMs evolve over time, as their behavior can change significantly within a relatively short period. By shedding light on the fluctuations in performance and behavior of GPT-3.5 and GPT-4, this study underscores the need for ongoing scrutiny of LLMs to ensure their reliability and effectiveness.\n\nThe full research paper can be accessed at: [link to the paper on arXiv](https://arxiv.org/abs/2307.09009)."
    },
    {
      "source_url": "",
      "type": "facts",
      "content": [
        {
          "fact": "A new research paper titled 'How is ChatGPT's behavior changing over time?' explores the evolution of two widely used large language models (LLMs), GPT-3.5 and GPT-4.",
          "check": true,
          "source": "https://arxiv.org/abs/2307.09009",
          "source_text": "arXiv-issued DOI via DataCite         Submission history From: Lingjiao Chen [ view email ]  [v1] Tue, 18 Jul 2023 06:56:08 UTC (536 KB)        Full-text links:  Download:   Download a PDF of the paper titled How is ChatGPT's behavior changing over time?, by Lingjiao Chen and Matei Zaharia and James Zou  PDF  Other formats  ( license )    Current browse context: cs.CL    <\u00a0prev   |   next\u00a0>",
          "source_start": "",
          "match_text": "A new research paper titled \"How is ChatGPT's behavior changing over time?\" explores the evolution of two widely used large language models (LLMs), GPT-3.5 and GPT-4.",
          "match_start": 91
        },
        {
          "fact": "Authored by Lingjiao Chen, Matei Zaharia, and James Zou, the paper delves into the opaque nature of updates made to these models over time.",
          "check": null,
          "source": "https://arxiv.org/abs/2307.09009#t=180",
          "source_text": "However, when and how these models are updated over time is opaque",
          "source_start": 180,
          "match_text": "Authored by Lingjiao Chen, Matei Zaharia, and James Zou, the paper delves into the opaque nature of updates made to these models over time.",
          "match_start": 258
        },
        {
          "fact": "The authors evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 across four diverse tasks: solving math problems, answering sensitive/dangerous questions, generating code, and visual reasoning.",
          "check": false,
          "source": null,
          "source_text": "",
          "source_start": "",
          "match_text": "The authors evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 across four diverse tasks: solving math problems, answering sensitive/dangerous questions, generating code, and visual reasoning.",
          "match_start": 398
        },
        {
          "fact": "GPT-4 (March 2023) displayed an impressive accuracy of 97.6% when identifying prime numbers.",
          "check": null,
          "source": "https://arxiv.org/abs/2307.09009#t=558",
          "source_text": "For example, GPT-4 (March 2023) was very good at identifying prime numbers (accuracy 97.6%)",
          "source_start": 558,
          "match_text": "GPT-4 (March 2023) displayed an impressive accuracy of 97.6% when identifying prime numbers.",
          "match_start": 748
        },
        {
          "fact": "However, GPT-4's performance on the same task dropped drastically to a mere 2.4% accuracy in June 2023.",
          "check": true,
          "source": "https://arxiv.org/abs/2307.09009",
          "source_text": "GPT-3.5 and GPT-4 are the two most widely used large language model (LLM)\nservices. However, when and how these models are updated over time is opaque.\nHere, we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 on\nfour diverse tasks: 1) solving math problems, 2) answering sensitive/dangerous\nquestions, 3) generating code and 4) visual reasoning. We find that the",
          "source_start": "",
          "match_text": "However, GPT-4's performance on the same task dropped drastically to a mere 2.4% accuracy in June 2023.",
          "match_start": 841
        },
        {
          "fact": "Both GPT-4 and GPT-3.5 exhibited more formatting mistakes in code generation in June than in March.",
          "check": true,
          "source": "https://arxiv.org/abs/2307.09009",
          "source_text": "services. However, when and how these models are updated over time is opaque.\nHere, we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 on\nfour diverse tasks: 1) solving math problems, 2) answering sensitive/dangerous\nquestions, 3) generating code and 4) visual reasoning. We find that the\nperformance and behavior of both GPT-3.5 and GPT-4 can vary greatly over time.",
          "source_start": "",
          "match_text": "GPT-4 and GPT-3.5 exhibited more formatting mistakes in code generation in June than in March. Thes",
          "match_start": 1184
        },
        {
          "fact": "The researchers emphasize the importance of understanding how LLMs evolve over time, as their behavior can change significantly within a relatively short period.",
          "check": true,
          "source": "https://arxiv.org/abs/2307.09009",
          "source_text": "How is ChatGPT's behavior changing over time?\n\nAuthors:Lingjiao Chen, Matei Zaharia, James Zou",
          "source_start": "",
          "match_text": "The researchers emphasize the importance of understanding how LLMs evolve over time, as their behavior can change significantly within a relatively short period.",
          "match_start": 1406
        },
        {
          "fact": "This study underscores the need for ongoing scrutiny of LLMs to ensure their reliability and effectiveness.",
          "check": true,
          "source": "https://arxiv.org/abs/2307.09009",
          "source_text": "arXiv-issued DOI via DataCite         Submission history From: Lingjiao Chen [ view email ]  [v1] Tue, 18 Jul 2023 06:56:08 UTC (536 KB)        Full-text links:  Download:   Download a PDF of the paper titled How is ChatGPT's behavior changing over time?, by Lingjiao Chen and Matei Zaharia and James Zou  PDF  Other formats  ( license )    Current browse context: cs.CL    <\u00a0prev   |   next\u00a0>",
          "source_start": "",
          "match_text": "study underscores the need for ongoing scrutiny of LLMs to ensure their reliability and effectiveness.\n\nThe",
          "match_start": 1661
        },
        {
          "fact": "The full research paper can be accessed at: [link to the paper on arXiv](https://arxiv.org/abs/2307.09009).",
          "check": null,
          "source": "https://arxiv.org/abs/2307.09009#t=1932",
          "source_text": "Download a PDF of the paper titled How is ChatGPT's behavior changing over time?, by Lingjiao Chen and Matei Zaharia and James Zou",
          "source_start": 1932,
          "match_text": "The full research paper can be accessed at: [link to the paper on arXiv](https://arxiv.org/abs/2307.09009).",
          "match_start": 1765
        },
        {
          "fact": "The paper delves into the opaque nature of updates made to these models over time.",
          "check": null,
          "source": "https://arxiv.org/abs/2307.09009#t=254",
          "source_text": "we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4",
          "source_start": 254,
          "match_text": "paper delves into the opaque nature of updates made to these models over time. The",
          "match_start": 319
        }
      ]
    }
  ],
  "filename": "1689777418-arxiv-2307.09009"
}