
<HTML>
<TITLE>The Dispatch</TITLE>
<STYLE>
.b-tab {
  padding: 20px;
  border: 1px solid #000;
  display: none;
}

.b-tab.active {
  display: block;
}

.b-nav-tab {
  display: inline-block;
  padding: 20px;
}

.b-nav-tab.active {
  color: #ff4200;
}
</STYLE>
<BODY>

<a href="#orange" data-tab="orange" class="b-nav-tab active">
  Article
</a>
<a href="#green" data-tab="green" class="b-nav-tab">
  Sources
</a>
<a href="#blue" data-tab="blue" class="b-nav-tab">
  Facts
</a>
<div id="orange" class="b-tab active">
  <p>How is ChatGPT's behavior changing over time?</p>
<p>By Lingjiao Chen, Matei Zaharia, James Zou</p>
<p>A new research paper titled "How is ChatGPT's behavior changing over time?" explores the evolution of two widely used large language models (LLMs), GPT-3.5 and GPT-4. <a href="https://arxiv.org/abs/2307.09009#t=180">Authored by Lingjiao Chen, Matei Zaharia, and James Zou, the paper delves into the opaque nature of updates made to these models over time.</a> <a href="None">The authors evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 across four diverse tasks: solving math problems, answering sensitive/dangerous questions, generating code, and visual reasoning.</a></p>
<p>The researchers discovered that both GPT-3.5 and GPT-4 exhibit significant variations in performance and behavior over time. For instance, <a href="https://arxiv.org/abs/2307.09009#t=558">GPT-4 (March 2023) displayed an impressive accuracy of 97.6% when identifying prime numbers.</a> <a href="https://arxiv.org/abs/2307.09009">However, GPT-4's performance on the same task dropped drastically to a mere 2.4% accuracy in June 2023.</a> Interestingly, GPT-3.5 (June 2023) outperformed its March 2023 counterpart in this particular task.</p>
<p>Another noteworthy finding was that GPT-4 became less willing to answer sensitive questions in June compared to March. Additionally, both GPT-4 and GPT-3.5 exhibited more formatting mistakes in code generation in June than in March. These observations highlight the dynamic nature of LLM behavior and the necessity for continuous monitoring of their quality.</p>
<p><a href="https://arxiv.org/abs/2307.09009">The researchers emphasize the importance of understanding how LLMs evolve over time, as their behavior can change significantly within a relatively short period.</a> By shedding light on the fluctuations in performance and behavior of GPT-3.5 and GPT-4, this study underscores the need for ongoing scrutiny of LLMs to ensure their reliability and effectiveness.</p>
<p><a href="https://arxiv.org/abs/2307.09009#t=1932">The full research paper can be accessed at: [link to the paper on arXiv](https://arxiv.org/abs/2307.09009).</a></p>
</div>
<div id="green" class="b-tab">
  [{"id": "2307.09009", "url": "https://arxiv.org/abs/2307.09009", "site": "arxiv"}]
</div>
<div id="blue" class="b-tab">
  [
  {
    "fact": "A new research paper titled 'How is ChatGPT's behavior changing over time?' explores the evolution of two widely used large language models (LLMs), GPT-3.5 and GPT-4.",
    "check": true,
    "source": "https://arxiv.org/abs/2307.09009",
    "source_text": "arXiv-issued DOI via DataCite         Submission history From: Lingjiao Chen [ view email ]  [v1] Tue, 18 Jul 2023 06:56:08 UTC (536 KB)        Full-text links:  Download:   Download a PDF of the paper titled How is ChatGPT's behavior changing over time?, by Lingjiao Chen and Matei Zaharia and James Zou  PDF  Other formats  ( license )    Current browse context: cs.CL    <\u00a0prev   |   next\u00a0>",
    "source_start": "",
    "match_text": "A new research paper titled \"How is ChatGPT's behavior changing over time?\" explores the evolution of two widely used large language models (LLMs), GPT-3.5 and GPT-4.",
    "match_start": 91
  },
  {
    "fact": "Authored by Lingjiao Chen, Matei Zaharia, and James Zou, the paper delves into the opaque nature of updates made to these models over time.",
    "check": null,
    "source": "https://arxiv.org/abs/2307.09009#t=180",
    "source_text": "However, when and how these models are updated over time is opaque",
    "source_start": 180,
    "match_text": "Authored by Lingjiao Chen, Matei Zaharia, and James Zou, the paper delves into the opaque nature of updates made to these models over time.",
    "match_start": 258
  },
  {
    "fact": "The authors evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 across four diverse tasks: solving math problems, answering sensitive/dangerous questions, generating code, and visual reasoning.",
    "check": false,
    "source": null,
    "source_text": "",
    "source_start": "",
    "match_text": "The authors evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 across four diverse tasks: solving math problems, answering sensitive/dangerous questions, generating code, and visual reasoning.",
    "match_start": 398
  },
  {
    "fact": "GPT-4 (March 2023) displayed an impressive accuracy of 97.6% when identifying prime numbers.",
    "check": null,
    "source": "https://arxiv.org/abs/2307.09009#t=558",
    "source_text": "For example, GPT-4 (March 2023) was very good at identifying prime numbers (accuracy 97.6%)",
    "source_start": 558,
    "match_text": "GPT-4 (March 2023) displayed an impressive accuracy of 97.6% when identifying prime numbers.",
    "match_start": 748
  },
  {
    "fact": "However, GPT-4's performance on the same task dropped drastically to a mere 2.4% accuracy in June 2023.",
    "check": true,
    "source": "https://arxiv.org/abs/2307.09009",
    "source_text": "GPT-3.5 and GPT-4 are the two most widely used large language model (LLM)\nservices. However, when and how these models are updated over time is opaque.\nHere, we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 on\nfour diverse tasks: 1) solving math problems, 2) answering sensitive/dangerous\nquestions, 3) generating code and 4) visual reasoning. We find that the",
    "source_start": "",
    "match_text": "However, GPT-4's performance on the same task dropped drastically to a mere 2.4% accuracy in June 2023.",
    "match_start": 841
  },
  {
    "fact": "Both GPT-4 and GPT-3.5 exhibited more formatting mistakes in code generation in June than in March.",
    "check": true,
    "source": "https://arxiv.org/abs/2307.09009",
    "source_text": "services. However, when and how these models are updated over time is opaque.\nHere, we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 on\nfour diverse tasks: 1) solving math problems, 2) answering sensitive/dangerous\nquestions, 3) generating code and 4) visual reasoning. We find that the\nperformance and behavior of both GPT-3.5 and GPT-4 can vary greatly over time.",
    "source_start": "",
    "match_text": "GPT-4 and GPT-3.5 exhibited more formatting mistakes in code generation in June than in March. Thes",
    "match_start": 1184
  },
  {
    "fact": "The researchers emphasize the importance of understanding how LLMs evolve over time, as their behavior can change significantly within a relatively short period.",
    "check": true,
    "source": "https://arxiv.org/abs/2307.09009",
    "source_text": "How is ChatGPT's behavior changing over time?\n\nAuthors:Lingjiao Chen, Matei Zaharia, James Zou",
    "source_start": "",
    "match_text": "The researchers emphasize the importance of understanding how LLMs evolve over time, as their behavior can change significantly within a relatively short period.",
    "match_start": 1406
  },
  {
    "fact": "This study underscores the need for ongoing scrutiny of LLMs to ensure their reliability and effectiveness.",
    "check": true,
    "source": "https://arxiv.org/abs/2307.09009",
    "source_text": "arXiv-issued DOI via DataCite         Submission history From: Lingjiao Chen [ view email ]  [v1] Tue, 18 Jul 2023 06:56:08 UTC (536 KB)        Full-text links:  Download:   Download a PDF of the paper titled How is ChatGPT's behavior changing over time?, by Lingjiao Chen and Matei Zaharia and James Zou  PDF  Other formats  ( license )    Current browse context: cs.CL    <\u00a0prev   |   next\u00a0>",
    "source_start": "",
    "match_text": "study underscores the need for ongoing scrutiny of LLMs to ensure their reliability and effectiveness.\n\nThe",
    "match_start": 1661
  },
  {
    "fact": "The full research paper can be accessed at: [link to the paper on arXiv](https://arxiv.org/abs/2307.09009).",
    "check": null,
    "source": "https://arxiv.org/abs/2307.09009#t=1932",
    "source_text": "Download a PDF of the paper titled How is ChatGPT's behavior changing over time?, by Lingjiao Chen and Matei Zaharia and James Zou",
    "source_start": 1932,
    "match_text": "The full research paper can be accessed at: [link to the paper on arXiv](https://arxiv.org/abs/2307.09009).",
    "match_start": 1765
  },
  {
    "fact": "The paper delves into the opaque nature of updates made to these models over time.",
    "check": null,
    "source": "https://arxiv.org/abs/2307.09009#t=254",
    "source_text": "we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4",
    "source_start": 254,
    "match_text": "paper delves into the opaque nature of updates made to these models over time. The",
    "match_start": 319
  }
]
</div>

</BODY>
<SCRIPT>
function Tabs() {
  var bindAll = function() {
    var menuElements = document.querySelectorAll('[data-tab]');
    for(var i = 0; i < menuElements.length ; i++) {
      menuElements[i].addEventListener('click', change, false);
    }
  }

  var clear = function() {
    var menuElements = document.querySelectorAll('[data-tab]');
    for(var i = 0; i < menuElements.length ; i++) {
      menuElements[i].classList.remove('active');
      var id = menuElements[i].getAttribute('data-tab');
      document.getElementById(id).classList.remove('active');
    }
  }

  var change = function(e) {
    clear();
    e.target.classList.add('active');
    var id = e.currentTarget.getAttribute('data-tab');
    document.getElementById(id).classList.add('active');
  }

  bindAll();
}

var connectTabs = new Tabs();
</SCRIPT>
</HTML>
